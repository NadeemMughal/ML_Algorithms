{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muhammad Nadeem\n",
    "# 201980050\n",
    "# BS Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "MPZy3W59kaGnpCBRJM3rNJ",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/0.7inner-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/0.7inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "GLpOUauead8U0tNkm4nurO",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/0.7outer-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/0.7outer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "kkL6zECBD2HEQ6IlZOufFM",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/0.9inner-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/0.9inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "3uYPM7qpnqnlFhKaKvifs2",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/0.9outer-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/0.9outer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "l8VibwCxmJuKajw43gGBN1",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.1inner-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.1inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "OpelelS1R3zh4G2nQD1YZQ",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.1outer-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.1outer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.3inner-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.3inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.3outer-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.3outer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.5inner-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.5inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.5outer-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.5outer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.7inner-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.7inner.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/1.7outer-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/1.7outer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/BRB-12-4-100watt.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/BRB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('./input/healthy.csv').drop(['Time Stamp', ' Current-B', ' Current-C'], axis = 1)[:100000]\n",
    "data.head()\n",
    "data.shape\n",
    "tranformed_df = pd.DataFrame(columns=range(1000))\n",
    "for i in range(0, 100000, 1000):\n",
    "    tranformed_df = tranformed_df.append(pd.DataFrame(np.array(data.iloc[i:i+1000].T), columns = range(1000)))\n",
    "tranformed_df\n",
    "tranformed_df.to_csv('./Output/healthy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# set the path to the directory containing the data files\n",
    "data_path = './Output/'\n",
    "\n",
    "# create an empty list to store the data frames\n",
    "dfs = []\n",
    "\n",
    "# loop through the data files and load them into data frames\n",
    "for filename in os.listdir(data_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(data_path, filename), header=None)\n",
    "        dfs.append(df)\n",
    "\n",
    "# concatenate the data frames into a single data frame\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv('./Output/FinalDataFrame.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def euclidean_distance(x1, x2):\n",
    "    distance = 0\n",
    "    for j in range(len(x1)):\n",
    "        distance += (x1[j] - x2[j])**2\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_train,output_train , test_point, k_):\n",
    "    distances = []\n",
    "    for index in range(len(input_train)):\n",
    "        dist = euclidean_distance(input_train.iloc[index,:], test_point)\n",
    "        distances.append((output_train.iloc[index], dist))\n",
    "\n",
    "    distances = sorted(distances, key=lambda x: x[1])\n",
    "    neighbors = distances[:k_]\n",
    "\n",
    "    classes = {}\n",
    "    for neighbor in neighbors:\n",
    "        label = neighbor[0]\n",
    "        if label in classes:\n",
    "            classes[label] += 1\n",
    "        else:\n",
    "            classes[label] = 1\n",
    "\n",
    "    return max(classes, key=classes.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>2.0965</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "      <td>2.0159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.1551</td>\n",
       "      <td>2.2137</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.7131</td>\n",
       "      <td>2.6093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>2.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>2.7094</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "      <td>2.3578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>2.6960</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "      <td>3.0171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1       2       3       4       5       6       7       8  \\\n",
       "649   2.0965  2.0965  2.0965  2.0965  2.0965  2.0965  2.0965  2.0965  2.0965   \n",
       "832   2.1551  2.1551  2.1551  2.1551  2.1551  2.1551  2.1551  2.1551  2.1551   \n",
       "1317  2.4945  2.4945  2.4945  2.4945  2.4945  2.4945  2.4945  2.4945  2.4945   \n",
       "1060  2.7094  2.7094  2.7094  2.7094  2.7094  2.7094  2.7094  2.7094  2.7094   \n",
       "633   2.6960  2.6960  2.6960  2.6960  2.6960  2.6960  2.6960  2.6960  2.6960   \n",
       "\n",
       "           9  ...     990     991     992     993     994     995     996  \\\n",
       "649   2.0965  ...  2.0159  2.0159  2.0159  2.0159  2.0159  2.0159  2.0159   \n",
       "832   2.2137  ...  2.7131  2.7131  2.7131  2.7131  2.7131  2.7131  2.7131   \n",
       "1317  2.4945  ...  2.2625  2.2625  2.2625  2.2625  2.2625  2.2625  2.2625   \n",
       "1060  2.7094  ...  2.3578  2.3578  2.3578  2.3578  2.3578  2.3578  2.3578   \n",
       "633   2.6960  ...  3.0171  3.0171  3.0171  3.0171  3.0171  3.0171  3.0171   \n",
       "\n",
       "         997     998     999  \n",
       "649   2.0159  2.0159  2.0159  \n",
       "832   2.7131  2.7131  2.6093  \n",
       "1317  2.2625  2.2625  2.2625  \n",
       "1060  2.3578  2.3578  2.3578  \n",
       "633   3.0171  3.0171  3.0171  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649     unhealthy1.3inner\n",
       "832     unhealthy1.5inner\n",
       "1317              healthy\n",
       "1060    unhealthy1.7inner\n",
       "633     unhealthy1.3inner\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>3.0415</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "      <td>2.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>2.2564</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "      <td>2.9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>2.0134</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>2.3614</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "      <td>3.0293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>3.0134</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "      <td>2.2625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1       2       3       4       5       6       7       8  \\\n",
       "836   3.0415  3.0415  3.0415  3.0415  3.0415  3.0415  3.0415  3.0415  3.0415   \n",
       "509   2.2564  2.2564  2.2564  2.2564  2.2564  2.2564  2.2564  2.2564  2.2564   \n",
       "665   2.0134  2.0134  2.0134  2.0134  2.0134  2.0134  2.0134  2.0134  2.0134   \n",
       "613   2.3614  2.3614  2.3614  2.3614  2.3614  2.3614  2.3614  2.3614  2.3614   \n",
       "1099  3.0134  3.0134  3.0134  3.0134  3.0134  3.0134  3.0134  3.0134  3.0134   \n",
       "\n",
       "           9  ...     990     991     992     993     994     995     996  \\\n",
       "836   3.0415  ...  2.0012  2.0012  2.0012  2.0012  2.0012  2.0012  2.0012   \n",
       "509   2.2564  ...  2.9841  2.9841  2.9841  2.9841  2.9841  2.9841  2.9841   \n",
       "665   2.0134  ...  3.0000  3.0000  3.0000  3.0000  3.0000  3.0000  3.0000   \n",
       "613   2.3614  ...  3.0293  3.0293  3.0293  3.0293  3.0293  3.0293  3.0293   \n",
       "1099  3.0134  ...  2.2625  2.2625  2.2625  2.2625  2.2625  2.2625  2.2625   \n",
       "\n",
       "         997     998     999  \n",
       "836   2.0012  2.0012  2.0012  \n",
       "509   2.9841  2.9841  2.9841  \n",
       "665   3.0000  3.0000  3.0000  \n",
       "613   3.0293  3.0293  3.0293  \n",
       "1099  2.2625  2.2625  2.2625  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836     unhealthy1.5inner\n",
       "509     unhealthy1.1outer\n",
       "665     unhealthy1.3inner\n",
       "613     unhealthy1.3inner\n",
       "1099    unhealthy1.7inner\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unhealthy1.5inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'healthy',\n",
       " 'healthy',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7inner',\n",
       " 'healthy',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'healthy',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.5outer',\n",
       " 'healthy',\n",
       " 'unhealthy0.9outer',\n",
       " 'label',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'label',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.7inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'healthy',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.1outer',\n",
       " 'healthy',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'healthy',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'healthy',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'healthy',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.1inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.7outer',\n",
       " 'label',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'healthy',\n",
       " 'unhealthy1.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'healthy',\n",
       " 'unhealthy0.9outer',\n",
       " 'healthy',\n",
       " 'healthy',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'healthy',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.9outer',\n",
       " 'healthy',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy0.7inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.3outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'healthy',\n",
       " 'unhealthy0.9inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.5outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy1.7inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy1.1inner',\n",
       " 'unhealthy0.9inner',\n",
       " 'label',\n",
       " 'unhealthy1.1outer',\n",
       " 'unhealthy0.9outer',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthyBRBMotor',\n",
       " 'unhealthy1.3inner',\n",
       " 'unhealthy1.7outer',\n",
       " 'unhealthy1.5inner',\n",
       " 'unhelthy0.7outer',\n",
       " 'unhealthy1.5outer']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "prediction = [predict(x_train, y_train, x_test.iloc[i], k) for i in range(len(x_test))]\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is  27.56183745583039 % accurate\n"
     ]
    }
   ],
   "source": [
    "print('Model is ',accuracy_score(y_true = y_test, y_pred = prediction) * 100,'% accurate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  27.4 %\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred = prediction, average='weighted')\n",
    "print(\"Precision: \", np.round(precision * 100, decimals=1),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 27.56183745583039 %\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_pred = prediction, average='weighted')\n",
    "print('Recall:', recall * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0,  0,  0,  2,  0,  0,  0,  0,  2,  0,  1,  0,  0],\n",
       "       [ 0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  3,  0,  4,  1,  0,  0,  0,  1,  3,  3,  0,  3,  1],\n",
       "       [ 3,  0,  2,  3,  3,  1,  1,  1,  1,  0,  0,  3,  2,  2,  2],\n",
       "       [ 0,  0,  3,  0,  8,  0,  0,  0,  0,  6,  1,  1,  0,  0,  3],\n",
       "       [ 2,  0,  0,  3,  0,  0,  2,  2,  0,  1,  2,  0,  2,  1,  1],\n",
       "       [ 1,  0,  0,  0,  0,  3,  5,  3,  1,  2,  1,  0,  2,  1,  0],\n",
       "       [ 1,  0,  0,  1,  0,  1,  2,  8,  0,  1,  1,  0,  2,  2,  1],\n",
       "       [ 0,  0,  0,  3,  0,  3,  2,  1,  4,  1,  1,  0,  0,  3,  0],\n",
       "       [ 0,  0,  0,  0,  3,  4,  0,  2,  0,  3,  1,  0,  0,  3,  6],\n",
       "       [ 4,  0,  1,  5,  0,  2,  0,  0,  0,  0,  1,  1,  2,  2,  2],\n",
       "       [ 0,  0,  2,  1,  0,  0,  0,  0,  3,  2,  0,  9,  0,  0,  2],\n",
       "       [ 1,  0,  0,  1,  0,  1,  1,  1,  4,  1,  0,  0,  8,  2,  0],\n",
       "       [ 2,  0,  2,  0,  1,  2,  2,  1,  1,  2,  0,  0,  3,  1,  0],\n",
       "       [ 0,  0,  6,  0,  1,  1,  0,  0,  1,  3,  1,  0,  0,  3,  6]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true = y_test, y_pred = prediction)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "sensitivity = cm[1,1] / (cm[1,1] + cm[1,1])\n",
    "print(\"Sensitivity:\", sensitivity * 100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
    "print(\"Specificity: \", np.round(specificity, decimals=1) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  27.0 %\n"
     ]
    }
   ],
   "source": [
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score: \", np.round(f1 * 100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic for binary class use built in Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9187279151943463\n",
      "Recall: 1.0\n",
      "Precision: 0.9187279151943463\n",
      "F1 Score: 0.9576427255985267\n",
      "Confusion Matrix: \n",
      "[[  0  23]\n",
      " [  0 260]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Load dataset and split into features and labels\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.replace({\"healthy\": 0, \"unhealthy\": 1})\n",
    "y_test = y_test.replace({\"healthy\": 0, \"unhealthy\": 1})\n",
    "# Create logistic regression model and train on training set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute classification measures\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic from Scratch for Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linear_pred = np.dot(X, self.weights) + self.bias\n",
    "            predictions = sigmoid(linear_pred)\n",
    "            y = y.astype('int')\n",
    "\n",
    "            dw = (1/n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/n_samples) * np.sum(predictions-y)\n",
    "\n",
    "            self.weights = self.weights - self.lr*dw\n",
    "            self.bias = self.bias - self.lr*db\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = sigmoid(linear_pred)\n",
    "        class_pred = [0 if y<=0.5 else 1 for y in y_pred]\n",
    "        return class_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on built in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MRDEA0~1.NAD\\AppData\\Local\\Temp/ipykernel_12000/201378820.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "clf = LogisticRegression(lr=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_pred, y_test):\n",
    "    return np.sum(y_pred==y_test)/len(y_test)\n",
    "\n",
    "acc = accuracy(y_pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on given csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9357142857142857\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('./Output/FinalDataFrameBinaryClass.csv')\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert target variable to numeric values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit logistic regression model\n",
    "clf = LogisticRegression(lr=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels and evaluate model accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression For multi class use Built in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9187279151943463\n",
      "Precision: 0.8440609821573499\n",
      "Recall: 0.9187279151943463\n",
      "F1 score: 0.8798131047901658\n",
      "Confusion matrix:\n",
      " [[  0  23]\n",
      " [  0 260]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('./Output/FinalDataFrame.csv')\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 score:\", f1)\n",
    "print(\"Confusion matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic From Scratch for Multi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    \n",
    "    e_z = np.exp(z - np.max(z, axis=0, keepdims=False))\n",
    "    return e_z / np.sum(e_z, axis=0, keepdims=False)\n",
    "\n",
    "\n",
    "class LogisticRegression():\n",
    "\n",
    "    def __init__(self, lr=0.001, n_iters=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros((n_features, len(np.unique(y))))\n",
    "        self.bias = np.zeros(len(np.unique(y)))\n",
    "\n",
    "        for i, c in enumerate(np.unique(y)):\n",
    "            y_one_vs_all = np.where(y == c, 1, 0)\n",
    "            for _ in range(self.n_iters):\n",
    "                linear_pred = np.dot(X, self.weights[:,i]) + self.bias[i]\n",
    "                predictions = softmax(linear_pred)\n",
    "\n",
    "                dw = (1/n_samples) * np.dot(X.T, (predictions - y_one_vs_all))\n",
    "                db = (1/n_samples) * np.sum(predictions - y_one_vs_all)\n",
    "\n",
    "                self.weights[:,i] = self.weights[:,i] - self.lr * dw\n",
    "                self.bias[i] = self.bias[i] - self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_pred = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = softmax(linear_pred)\n",
    "        class_pred = np.argmax(y_pred, axis=1)\n",
    "        return class_pred\n",
    "\n",
    "    def accuracy(y_pred, y_test):\n",
    "        return np.sum(y_pred==y_test)/len(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06428571428571428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('./Output/FinalDataFrame.csv')\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Convert target variable to numeric values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit logistic regression model\n",
    "clf = LogisticRegression(lr=0.01)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels and evaluate model accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_pred, y_test)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
